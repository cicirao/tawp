<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Main thesis</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" media="screen,print" href="css/reset.css" />
    <script src="css/modernizr.custom.99475.js"></script>
    <link rel="stylesheet" href="css/screen.css" />
    <link rel="icon" href="css/gfx/favicon.ico" type="image/x-icon" />
  </head>
  <body>
    <main>
      <article id="what-is-practical-impact">
      <h2>
        What is “practical impact”?  It's when research informs practice.
      </h2>
        <p>
          Practitioners do things.  Researchers study how and why practitioners do the things they do.  Ideally, when researchers identify some previously unknown correlation between what practitioners do and the results they achieve, the practitioners can use that knowledge to improve their ability to get the result they want.
        </p>
        <p>
          This conversion of knowledge gained by researchers into a tool useable by practitioners is what I'm calling “practical impact”.
        </p>
      </article>
      <article id="why-is-practical-impact-interesting">
      <h2>
        Why is the “practical impact” of research interesting?
      </h2>
        <section>
        <h3>
          On-going empirical research into trivial correlations in social sciences
        </h3>
          <p>
            As evidenced by Schwab et al. (2011), in the social sciences it is often the case that merely demonstrating that an empirical study achieves statistical significant is considered the same as demonstrating that the study represents knowledge important enough to warrant being published.
          <p>
          <p>
            However, these days very large data sets are easy to find and even easier to analyze (when compared to earlier parts of the twentieth century, which is when most empirical methods were being developed and popularized), and such data have an inherently massive statistical power.  Meaning that they make it possible to separate even the tiniest of correlations between elements in that data from the statistical “noise” of synchronous yet random variations in the same data.
          <p>
          <p>
            Such inevitable correlations, while statistically significant, are often trivial when judged by any other measure.  [Schwab talks about…]
          <p>
          <p>
            What I propose is to judge these inevitable correlations by whether or not they become a tool for use by practitioners.  Especially in the social sciences, where controlled experiments are difficult if not impossible, the best confirmation of both the existence and the importance of a phenomenon is when the knowledge about that phenomenon is taken up by practitioners.
          <p>
        </section>
        <section>
        <h3>
          Lack of relevance in management research
        </h3>
          <p>
            <!--[need to go mining in my Org Comm. paper]-->
          </p>
        </section>
        <section>
        <h3>
          Increasing demand to demonstrate practical value of research by funding agencies
        </h3>
          <p>
            The HEFCE is intending to use the value of research to practitioners as part of its decision process for what research it will recommend gets ongoing government funding.  Other European institutions are doing similar things [pull refs from HEFCE-REF overview paper].
          <p>
        </section>
        <section>
        <h3>
          Value of practical impact may not be captured by citation metrics
        </h3>
          <p>
            As funding agencies begin to track and use information of the practical value of research, research institutions themselves will need to start keeping an eye on the same thing.  Currently in academia, research is most often judged using various bibliometrics, all of which are tied to citations in academic journals.  But citation-based informetrics are almost entirely isolated to academia, and gather no information from practice or practitioners.
          <p>
          <p>
            So, “practical impact” is not being directly captured by citation-based metrics.  Over the long term, adoption of a given piece of research knowledge will eventually circle back around and increase the citation metrics of the orignal publication, through the citations of researchers working on new studies who observe the knowledge being used in practice, and reference it.
          </p>
          <p>
            But that cycle will be slow and lossy, as it is dependent on researchers not only recognizing the use of knowledge from previous research, but also recognizing where it came from and citing that source when they publish their own work.
          </p>
          <p>
            So, citation-based metrics might reflect “practical impact”, but they do not capture it in a timely or accurate manner.
          </p>
        </section>
      </article>
    </main>
    <footer>
    </footer>
  </body>
</html>
